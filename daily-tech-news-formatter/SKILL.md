---
name: daily-tech-news-formatter
description: Multi-round content optimization engine for WeChat compliance, grammar refinement, punctuation normalization, and title enhancement. Generates format_report.md with before/after comparisons.
---

# Daily Tech News Formatter

> **ğŸ¨ Multi-Round Optimization Engine**: 5-8 rounds of systematic content refinement with quality tracking

## When to Use This Skill

Use this skill when you need to:
- Optimize WeChat article content for compliance and readability
- Apply 100+ sensitive keyword substitutions automatically
- Normalize all Chinese punctuation marks (ï¼Œã€‚ï¼šï¼ˆï¼‰ï¼etc.)
- Enhance headlines and section titles for engagement
- Perform grammar and semantic improvements
- Generate comprehensive formatting reports with before/after comparisons

**IMPORTANT**: This skill is designed to run automatically in the workflow pipeline after writing. It MUST generate `format_report.md` - the workflow will check for this file's existence and completeness.

## Quick Start

```bash
ä½¿ç”¨ daily-tech-news-formatter skill [input-file]
```

**Execution Time**: 4-6 minutes
**Input**: `tech_news_[YYYYMMDD]_wechat_draft.md` (from daily-tech-news-writer)
**Output**: `format_report_[YYYYMMDD].md` + `tech_news_[YYYYMMDD]_wechat_final.md`

## Core Optimization Rounds (Mandatory)

### Round 1: Compliance Optimization (åˆè§„æ€§ä¼˜åŒ–)

**Purpose**: Apply sensitive keyword substitutions to ensure WeChat publication safety

**Hardcoded Rules**:
```yaml
Risk_Tier_High: # ğŸ”´ Must neutralize
  Military_Defense:
    - "äº”è§’å¤§æ¥¼" â†’ "ç¾å›½å›½é˜²éƒ¨" / "ç¾å›½æ”¿åºœ"
    - "å†›äº‹åˆåŒ" â†’ "æ”¿åºœç ”å‘åˆä½œ" / "å›½é˜²é¡¹ç›®åˆä½œ"
    - "å†›ç”¨" â†’ "æ”¿åºœåº”ç”¨" / "ç‰¹æ®Šé¢†åŸŸåº”ç”¨"
    - "å›½é˜²éƒ¨" â†’ "æ”¿åºœéƒ¨é—¨" (when in negative context)

  US_China_Confrontation:
    - "ä¸­ç¾å¯¹æŠ—" â†’ "ä¸­ç¾å…³ç³»è°ƒæ•´" / "å›½é™…æ ¼å±€å˜åŒ–"
    - "ä¸­ç¾ç§‘æŠ€æˆ˜" â†’ "ä¸­ç¾ç§‘æŠ€æ”¿ç­–å·®å¼‚"
    - "åˆ¶è£" â†’ "æ”¿ç­–é™åˆ¶" / "å‡ºå£ç®¡æ§"
    - "ç¦ä»¤" â†’ "é™åˆ¶æªæ–½" / "æ”¿ç­–è°ƒæ•´"
    - "èŠ¯ç‰‡æˆ˜" â†’ "åŠå¯¼ä½“æ”¿ç­–è°ƒæ•´"
    - "å°é”" â†’ "é™åˆ¶" / "ç®¡æ§"

  Minor_Related: # Extremely sensitive
    - Avoid any negative framing of minor-related incidents
    - If unavoidable, focus on solutions/improvements only
    - Never use: "æœªæˆå¹´äººæ²‰è¿·", "é’å°‘å¹´é—®é¢˜"
    - Prefer: "é’å°‘å¹´ä¿æŠ¤æªæ–½", "å®¶é•¿ç›‘æŠ¤åŠŸèƒ½"

Risk_Tier_Medium: # ğŸŸ¡ Add disclaimers
  Financial_Data:
    - ANY funding amount â†’ Add: "ï¼ˆæ ¹æ®å…¬å¼€æŠ¥é“ï¼Œæœªç»å®˜æ–¹ç¡®è®¤ï¼‰"
    - Stock prices â†’ Add: "ï¼ˆæ•°æ®æ¥æºï¼š[source]ï¼Œä»…ä¾›å‚è€ƒï¼‰"
    - Revenue/profit â†’ Add: "ï¼ˆä»¥å…¬å¸è´¢æŠ¥ä¸ºå‡†ï¼‰"
    - Valuation â†’ Add: "ï¼ˆå¸‚åœºä¼°ç®—ï¼Œéå®˜æ–¹æ•°æ®ï¼‰"

  Policy_Changes:
    - Government regulations â†’ Add: "ï¼ˆå…·ä½“æ”¿ç­–ä»¥å®˜æ–¹å…¬å‘Šä¸ºå‡†ï¼‰"
    - Regulatory actions â†’ Use neutral tone, cite official sources
    - Policy predictions â†’ Add: "ï¼ˆåŸºäºå½“å‰ä¿¡æ¯åˆ†æï¼Œå®é™…æƒ…å†µå¯èƒ½å˜åŒ–ï¼‰"

  Market_Speculation:
    - Avoid: "æš´æ¶¨"ã€"ç‹‚è·Œ"ã€"å´©ç›˜"
    - Use: "æ˜¾è‘—å¢é•¿"ã€"å¤§å¹…ä¸‹é™"ã€"å¸‚åœºè°ƒæ•´"
    - Any prediction â†’ Add disclaimer

Risk_Tier_Low: # ğŸŸ¢ Normal reporting
  Product_Launches:
    - Standard reporting, no special treatment
    - Verify product names and specs accuracy

  Funding_News:
    - Report as announced
    - Always cite source

  Technical_Progress:
    - Celebrate achievements objectively
    - No excessive superlatives
```

**Substitution Process**:
```python
def apply_compliance_substitutions(content):
    """
    Apply 100+ keyword substitutions with context awareness
    """
    substitutions = load_substitution_rules()
    changes_log = []

    for pattern, replacement, risk_level, context_rules in substitutions:
        # Context-aware replacement
        matches = find_with_context(content, pattern, context_window=50)

        for match in matches:
            # Check context rules
            if should_replace(match, context_rules):
                before = match.text
                after = apply_replacement(match, replacement)

                content = content.replace(before, after)
                changes_log.append({
                    'pattern': pattern,
                    'before': before,
                    'after': after,
                    'risk_level': risk_level,
                    'location': match.line_number
                })

    return content, changes_log

def should_replace(match, context_rules):
    """
    Determine if replacement should be applied based on context
    """
    # Some words are OK in positive contexts
    if context_rules.get('allow_positive'):
        if is_positive_context(match.surrounding_text):
            return False

    # Some words always replace in certain sections
    if context_rules.get('section_blacklist'):
        if match.section in context_rules['section_blacklist']:
            return True

    return True  # Default: replace
```

**Output**:
```markdown
### Round 1: Compliance Optimization

**Changes Applied**: 23 substitutions

#### High-Risk Changes (ğŸ”´)
1. Line 45: "äº”è§’å¤§æ¥¼åˆåŒ" â†’ "ç¾å›½æ”¿åºœç ”å‘åˆä½œ"
2. Line 102: "ä¸­ç¾ç§‘æŠ€æˆ˜å‡çº§" â†’ "ä¸­ç¾ç§‘æŠ€æ”¿ç­–å·®å¼‚åŠ å¤§"
3. Line 156: "èŠ¯ç‰‡ç¦ä»¤" â†’ "èŠ¯ç‰‡å‡ºå£é™åˆ¶æªæ–½"
[... 8 more high-risk changes ...]

#### Medium-Risk Enhancements (ğŸŸ¡)
1. Line 78: Added disclaimer to "$500M funding round"
   â†’ "$500Mèèµ„ï¼ˆæ ¹æ®å…¬å¼€æŠ¥é“ï¼Œæœªç»å®˜æ–¹ç¡®è®¤ï¼‰"
2. Line 134: Added disclaimer to "stock price surge"
   â†’ "è‚¡ä»·æ˜¾è‘—ä¸Šæ¶¨ï¼ˆæ•°æ®æ¥æºï¼šBloombergï¼Œä»…ä¾›å‚è€ƒï¼‰"
[... 7 more medium-risk changes ...]

#### Low-Risk Improvements (ğŸŸ¢)
1. Line 210: "æš´æ¶¨" â†’ "æ˜¾è‘—å¢é•¿"
2. Line 287: "ç‹‚è·Œ" â†’ "å¤§å¹…ä¸‹é™"
[... 5 more low-risk changes ...]

**Compliance Score**: âœ… 95/100 (Excellent - ready for publication)
```

### Round 2: Punctuation Normalization (æ ‡ç‚¹ç¬¦å·æ ‡å‡†åŒ–)

**Purpose**: Convert all English punctuation in Chinese content to Chinese punctuation

**Hardcoded Rules**:
```yaml
English_to_Chinese:
  - "," â†’ "ï¼Œ" (comma, when in Chinese context)
  - "." â†’ "ã€‚" (period, when end of Chinese sentence)
  - ":" â†’ "ï¼š" (colon, when followed by Chinese)
  - ";" â†’ "ï¼›" (semicolon, in Chinese context)
  - "!" â†’ "ï¼" (exclamation, in Chinese context)
  - "?" â†’ "ï¼Ÿ" (question mark, in Chinese context)
  - "(" â†’ "ï¼ˆ" (left paren, in Chinese context)
  - ")" â†’ "ï¼‰" (right paren, in Chinese context)
  - "\"" â†’ """ (left quote) or """ (right quote)
  - "'" â†’ "'" (left single) or "'" (right single)

Context_Rules:
  Preserve_English_Punctuation:
    - Inside English words/phrases
    - URLs and technical identifiers
    - Code snippets
    - Product version numbers (e.g., "GPT-4.5")
    - Email addresses
    - Abbreviations (e.g., "U.S.", "Ph.D.")

  Smart_Quote_Matching:
    - Track quote depth for nested quotes
    - Use " " for outer quotes, ' ' for inner quotes
    - Example: ä»–è¯´ï¼š"å¥¹å›ç­”'æˆ‘ä¸çŸ¥é“'ã€‚"

  Mixed_Content:
    - "OpenAIå‘å¸ƒGPT-5" (preserve hyphen in GPT-5)
    - "CEOè¯´ï¼Œè¿™æ˜¯é‡å¤§çªç ´" (use Chinese comma after Chinese text)
    - "æ ¹æ®TechCrunchæŠ¥é“ï¼Œ..." (Chinese comma after source name)
```

**Detection and Replacement**:
```python
def normalize_punctuation(content):
    """
    Intelligently replace English punctuation with Chinese equivalents
    """
    changes_log = []
    char_contexts = analyze_character_contexts(content)

    for i, char in enumerate(content):
        if char not in ENGLISH_PUNCTUATION:
            continue

        context = char_contexts[i]

        # Skip if in English context
        if is_english_context(context):
            continue

        # Skip if in preserved context
        if is_preserved_context(context):
            continue

        # Apply replacement
        chinese_equiv = get_chinese_equivalent(char, context)
        if chinese_equiv:
            before = content[max(0, i-10):min(len(content), i+10)]
            content = content[:i] + chinese_equiv + content[i+1:]
            after = content[max(0, i-10):min(len(content), i+10)]

            changes_log.append({
                'position': i,
                'before': char,
                'after': chinese_equiv,
                'context': before + ' â†’ ' + after
            })

    return content, changes_log

def is_english_context(context):
    """
    Check if surrounding text is primarily English
    """
    surrounding = context['before'] + context['after']
    ascii_ratio = sum(ord(c) < 128 for c in surrounding) / len(surrounding)
    return ascii_ratio > 0.7

def is_preserved_context(context):
    """
    Check if this is a special context where English punctuation should be preserved
    """
    # URL detection
    if 'http' in context['before'] or '.com' in context['after']:
        return True

    # Version number detection (e.g., GPT-4.5)
    if re.match(r'[A-Za-z]+-?\d+\.?\d*', context['before'] + context['current'] + context['after']):
        return True

    # Code snippet detection
    if context['section_type'] == 'code':
        return True

    return False
```

**Output**:
```markdown
### Round 2: Punctuation Normalization

**Changes Applied**: 187 punctuation marks normalized

#### By Punctuation Type
| Type | English | Chinese | Count |
|------|---------|---------|-------|
| Comma | , | ï¼Œ| 65 |
| Period | . | ã€‚| 48 |
| Colon | : | ï¼š| 23 |
| Parentheses | () | ï¼ˆï¼‰| 18 pairs |
| Quotes | "" | ""| 15 pairs |
| Exclamation | ! | ï¼| 12 |
| Question | ? | ï¼Ÿ| 6 |

#### Preserved Contexts
- URLs: 34 instances
- Product versions: 12 instances (e.g., "GPT-4", "Claude-3.5")
- Technical terms: 8 instances
- English phrases: 15 instances

#### Sample Changes
1. Line 23: "OpenAIå®£å¸ƒ, æ–°æ¨¡å‹å°†..." â†’ "OpenAIå®£å¸ƒï¼Œæ–°æ¨¡å‹å°†..."
2. Line 67: "CEOè¡¨ç¤º: \"è¿™æ˜¯çªç ´\"" â†’ "CEOè¡¨ç¤ºï¼š"è¿™æ˜¯çªç ´""
3. Line 143: "ä¸‰ä¸ªä¸»è¦ç‰¹ç‚¹(æ€§èƒ½, æˆæœ¬, æ•ˆç‡)" â†’ "ä¸‰ä¸ªä¸»è¦ç‰¹ç‚¹ï¼ˆæ€§èƒ½ï¼Œæˆæœ¬ï¼Œæ•ˆç‡ï¼‰"

**Normalization Score**: âœ… 100% Chinese punctuation in Chinese content
```

### Round 3: Grammar and Semantic Optimization (è¯­æ³•è¯­ä¹‰ä¼˜åŒ–)

**Purpose**: Improve sentence structure, fix grammar errors, enhance clarity and flow

**Optimization Categories**:
```yaml
Sentence_Structure:
  - Fix run-on sentences (split into 2-3 shorter sentences)
  - Eliminate dangling modifiers
  - Improve parallel structure in lists
  - Reduce nested clauses (max 2 levels)

Word_Choice:
  - Replace vague terms with specific ones
  - Eliminate redundancy (e.g., "è¿‡å»çš„å†å²" â†’ "å†å²")
  - Use active voice instead of passive (when appropriate)
  - Improve transitions between paragraphs

Clarity:
  - Simplify complex technical jargon (add brief explanations)
  - Define acronyms on first use
  - Add context for unfamiliar company names
  - Clarify ambiguous pronoun references

Tone:
  - Maintain professional, objective tone
  - Remove overly promotional language
  - Balance enthusiasm with factual reporting
  - Consistent voice throughout article

Flow:
  - Improve topic sentences
  - Add transitional phrases
  - Ensure logical paragraph progression
  - Smooth section transitions
```

**Optimization Process**:
```python
def optimize_grammar_semantics(content):
    """
    Multi-pass optimization for grammar and meaning
    """
    changes_log = []

    # Pass 1: Sentence-level fixes
    sentences = split_into_sentences(content)
    for i, sent in enumerate(sentences):
        # Check sentence length
        if len(sent) > 100:  # Too long
            shorter_sents, reason = split_long_sentence(sent)
            sentences[i:i+1] = shorter_sents
            changes_log.append({
                'type': 'sentence_split',
                'before': sent,
                'after': shorter_sents,
                'reason': reason
            })

        # Fix common grammar issues
        fixed, grammar_changes = fix_grammar_issues(sent)
        if fixed != sent:
            sentences[i] = fixed
            changes_log.extend(grammar_changes)

    # Pass 2: Paragraph-level improvements
    paragraphs = group_into_paragraphs(sentences)
    for para in paragraphs:
        # Improve transitions
        improved, transition_changes = improve_transitions(para)
        if improved != para:
            changes_log.extend(transition_changes)

        # Enhance topic sentences
        improved, topic_changes = enhance_topic_sentence(para)
        if improved != para:
            changes_log.extend(topic_changes)

    # Pass 3: Document-level consistency
    final_content = '\n\n'.join(paragraphs)
    final_content, consistency_changes = ensure_consistency(final_content)
    changes_log.extend(consistency_changes)

    return final_content, changes_log
```

**Output**:
```markdown
### Round 3: Grammar and Semantic Optimization

**Changes Applied**: 42 improvements

#### Sentence Structure (15 changes)
1. Line 34: Split long sentence (125 chars â†’ 2 sentences of 68 + 57 chars)
   **Before**: "OpenAIå‘å¸ƒäº†GPT-5æ¨¡å‹ï¼Œè¿™ä¸ªæ¨¡å‹å…·æœ‰10ä¸‡äº¿å‚æ•°ï¼Œæ”¯æŒå¤šæ¨¡æ€èƒ½åŠ›åŒ…æ‹¬æ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘å’Œè§†é¢‘ï¼Œå¹¶ä¸”èƒ½å¤Ÿè¿›è¡Œé«˜çº§æ¨ç†å’Œå®æ—¶äº¤äº’ï¼Œé¢„è®¡å°†åœ¨2025å¹´ç¬¬äºŒå­£åº¦é€šè¿‡APIå‘å¼€å‘è€…å¼€æ”¾ã€‚"
   **After**: "OpenAIå‘å¸ƒäº†GPT-5æ¨¡å‹ï¼Œè¿™ä¸ªæ¨¡å‹å…·æœ‰10ä¸‡äº¿å‚æ•°ï¼Œæ”¯æŒæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘å’Œè§†é¢‘ç­‰å¤šæ¨¡æ€èƒ½åŠ›ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿè¿›è¡Œé«˜çº§æ¨ç†å’Œå®æ—¶äº¤äº’ï¼Œé¢„è®¡å°†åœ¨2025å¹´ç¬¬äºŒå­£åº¦é€šè¿‡APIå‘å¼€å‘è€…å¼€æ”¾ã€‚"

2. Line 89: Fixed dangling modifier
   **Before**: "ä½œä¸ºAIé¢†åŸŸçš„é¢†å¯¼è€…ï¼Œè¯¥å…¬å¸çš„æ–°äº§å“å¤‡å—æœŸå¾…ã€‚"
   **After**: "OpenAIä½œä¸ºAIé¢†åŸŸçš„é¢†å¯¼è€…ï¼Œå…¶æ–°äº§å“å¤‡å—æœŸå¾…ã€‚"

[... 13 more sentence structure improvements ...]

#### Word Choice (12 changes)
1. Line 45: Replaced vague term with specific one
   **Before**: "å–å¾—äº†å¾ˆå¤§çš„è¿›å±•"
   **After**: "åœ¨æ¨¡å‹æ€§èƒ½ä¸Šæå‡äº†40%"

2. Line 103: Eliminated redundancy
   **Before**: "è¿‡å»çš„å†å²æ•°æ®æ˜¾ç¤º"
   **After**: "å†å²æ•°æ®æ˜¾ç¤º"

[... 10 more word choice improvements ...]

#### Clarity Enhancements (10 changes)
1. Line 67: Defined acronym on first use
   **Before**: "RLHFæŠ€æœ¯æ˜¾è‘—æå‡äº†æ¨¡å‹è¡¨ç°"
   **After**: "RLHFï¼ˆåŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼‰æŠ€æœ¯æ˜¾è‘—æå‡äº†æ¨¡å‹è¡¨ç°"

2. Line 145: Added context for company name
   **Before**: "Cohereå®£å¸ƒæ–°ä¸€è½®èèµ„"
   **After**: "AIåˆåˆ›å…¬å¸Cohereå®£å¸ƒæ–°ä¸€è½®èèµ„"

[... 8 more clarity enhancements ...]

#### Tone Adjustments (5 changes)
1. Line 78: Removed overly promotional language
   **Before**: "è¿™æ¬¾é©å‘½æ€§çš„äº§å“å°†å½»åº•æ”¹å˜è¡Œä¸š"
   **After**: "è¿™æ¬¾äº§å“æœ‰æœ›ä¸ºè¡Œä¸šå¸¦æ¥é‡è¦å˜é©"

[... 4 more tone adjustments ...]

**Optimization Score**: âœ… 92/100 (Significant improvements in readability and clarity)
```

### Round 4: Title and Headline Enhancement (æ ‡é¢˜ä¼˜åŒ–)

**Purpose**: Optimize main title, section headings, and item headlines for engagement and clarity

**Optimization Strategies**:
```yaml
Main_Title_Rules:
  Length: 15-30 characters (optimal for WeChat feed)
  Pattern: "[æ—¶é—´èŒƒå›´] + [æ ¸å¿ƒä¸»é¢˜] + [å¸å¼•ç‚¹]"
  Examples:
    - "æœ¬å‘¨AIç§‘æŠ€åŠ¨æ€ | OpenAIå‘å¸ƒGPT-5"
    - "11æœˆç§‘æŠ€æ–°é—»æ±‡æ€» | äº”å¤§AIçªç ´"
    - "48å°æ—¶ç„¦ç‚¹ | AIæŠ•èµ„åˆ›å†å²æ–°é«˜"

  Avoid:
    - Generic titles ("ç§‘æŠ€æ–°é—»")
    - Clickbait ("éœ‡æƒŠï¼")
    - ALL CAPS
    - Excessive punctuation ("!!!")

Section_Heading_Rules:
  Format: "Emoji + Category Name"
  Length: 5-12 characters
  Clear hierarchy: Use ## for main sections, ### for subsections

  Examples:
    - "ğŸ‡¨ğŸ‡³ å›½å†…ç§‘æŠ€åŠ¨æ€"
    - "ğŸ¤– AIå…¬å¸æ–°é—»"
    - "ğŸ’° èèµ„ä¸æŠ•èµ„"
    - "ğŸ“± äº§å“å‘å¸ƒ"

Item_Headline_Rules:
  Pattern: "[Company] + [Action Verb] + [Key Point]"
  Length: 20-40 characters
  Include key data when relevant

  Good Examples:
    - "OpenAIå‘å¸ƒGPT-5ï¼Œå‚æ•°è¾¾10ä¸‡äº¿"
    - "Anthropicè·50äº¿ç¾å…ƒèèµ„ï¼Œä¼°å€¼ç¿»å€"
    - "NVIDIAæ¨å‡ºBlackwellæ¶æ„ï¼ŒAIæ€§èƒ½æå‡5å€"

  Avoid:
    - Vague headlines ("OpenAIæœ‰æ–°åŠ¨ä½œ")
    - Missing key data ("èèµ„æˆåŠŸ")
    - Overly long (>50 chars)
```

**Enhancement Process**:
```python
def enhance_titles(content):
    """
    Optimize all titles and headlines for engagement
    """
    changes_log = []

    # Main title optimization
    main_title = extract_main_title(content)
    if not is_optimal_title(main_title):
        enhanced_title, reason = optimize_main_title(main_title, content)
        content = content.replace(main_title, enhanced_title, 1)
        changes_log.append({
            'type': 'main_title',
            'before': main_title,
            'after': enhanced_title,
            'reason': reason,
            'improvement_score': calculate_title_score(enhanced_title)
        })

    # Section headings optimization
    section_headings = extract_section_headings(content)
    for heading in section_headings:
        if not has_emoji(heading) or not is_clear(heading):
            enhanced_heading = optimize_section_heading(heading)
            content = content.replace(heading, enhanced_heading)
            changes_log.append({
                'type': 'section_heading',
                'before': heading,
                'after': enhanced_heading
            })

    # Item headlines optimization
    item_headlines = extract_item_headlines(content)
    for headline in item_headlines:
        score = score_headline(headline)
        if score < 7.0:  # Below acceptable threshold
            enhanced_headline = optimize_item_headline(headline)
            content = content.replace(headline, enhanced_headline)
            changes_log.append({
                'type': 'item_headline',
                'before': headline,
                'after': enhanced_headline,
                'score_before': score,
                'score_after': score_headline(enhanced_headline)
            })

    return content, changes_log

def optimize_main_title(title, content):
    """
    Create engaging main title based on content highlights
    """
    # Extract date range
    date_range = extract_date_range(content)

    # Identify top highlight (most important/engaging item)
    top_item = identify_top_highlight(content)

    # Generate title pattern
    if top_item:
        new_title = f"{date_range} | {top_item['company']}{top_item['action']}"
        reason = f"Highlighted top story: {top_item['headline']}"
    else:
        new_title = f"{date_range} | AIç§‘æŠ€åŠ¨æ€æ±‡æ€»"
        reason = "Generic title with clear time range"

    return new_title, reason

def score_headline(headline):
    """
    Score headline quality (0-10)
    """
    score = 5.0  # Start with baseline

    # Length check
    length = len(headline)
    if 20 <= length <= 40:
        score += 2.0
    elif length < 20 or length > 50:
        score -= 1.0

    # Has company name
    if has_company_name(headline):
        score += 1.0

    # Has action verb
    if has_action_verb(headline):
        score += 1.0

    # Has key data
    if has_key_data(headline):
        score += 1.0

    # Clarity (no vague terms)
    if not has_vague_terms(headline):
        score += 0.5

    return min(10.0, max(0.0, score))
```

**Output**:
```markdown
### Round 4: Title and Headline Enhancement

**Changes Applied**: 28 improvements

#### Main Title
**Before**: "ç§‘æŠ€æ–°é—»æ±‡æ€»"
**After**: "æœ¬å‘¨AIç„¦ç‚¹ | OpenAIå‘å¸ƒGPT-5ï¼ŒNVIDIAä¸šç»©åˆ›æ–°é«˜"
**Reason**: Added specific highlights and time context
**Score**: 3.5/10 â†’ 8.5/10

#### Section Headings (8 improvements)
1. "å›½å†…æ–°é—»" â†’ "ğŸ‡¨ğŸ‡³ å›½å†…ç§‘æŠ€åŠ¨æ€"
2. "AIå…¬å¸" â†’ "ğŸ¤– AIå…¬å¸æ–°é—»"
3. "èèµ„æ¶ˆæ¯" â†’ "ğŸ’° èèµ„ä¸æŠ•èµ„"
[... 5 more section heading improvements ...]

#### Item Headlines (19 improvements)
1. Line 45:
   **Before**: "OpenAIå‘å¸ƒæ–°æ¨¡å‹"
   **After**: "OpenAIå‘å¸ƒGPT-5ï¼Œå‚æ•°è§„æ¨¡è¾¾10ä¸‡äº¿"
   **Score**: 4.0/10 â†’ 8.5/10
   **Improvement**: Added specific product name and key metric

2. Line 89:
   **Before**: "Anthropicè·å¾—èèµ„"
   **After**: "Anthropicè·Amazon 50äº¿ç¾å…ƒæŠ•èµ„ï¼Œä¼°å€¼è¾¾200äº¿"
   **Score**: 3.5/10 â†’ 9.0/10
   **Improvement**: Added investor, amount, and valuation

3. Line 134:
   **Before**: "NVIDIAä¸šç»©è¡¨ç°è‰¯å¥½"
   **After**: "NVIDIA Q3è¥æ”¶181äº¿ç¾å…ƒï¼ŒåŒæ¯”å¢é•¿206%"
   **Score**: 4.5/10 â†’ 8.0/10
   **Improvement**: Replaced vague term with specific metrics

[... 16 more item headline improvements ...]

**Average Headline Score**: 4.2/10 â†’ 8.3/10 (+4.1 improvement)
```

### Round 5: Final Quality Assurance (æœ€ç»ˆè´¨é‡æ£€æŸ¥)

**Purpose**: Comprehensive final check for consistency, accuracy, and publication readiness

**Verification Checklist**:
```yaml
Content_Verification:
  - All company names spelled consistently
  - All product names accurate and up-to-date
  - All numbers and metrics formatted consistently (e.g., "10ä¸‡äº¿" vs "10trillion")
  - All dates in same format (YYYYå¹´MMæœˆDDæ—¥)
  - All currencies properly labeled (ç¾å…ƒ, äººæ°‘å¸)

Structure_Verification:
  - Table of contents matches actual sections
  - All internal links working (if any)
  - Consistent heading hierarchy (no skipped levels)
  - Balanced section lengths (no 10-line section next to 200-line section)
  - "48å°æ—¶ç„¦ç‚¹" has exactly 5 items

Compliance_Final_Check:
  - No high-risk keywords remain
  - All disclaimers present where required
  - Financial data properly qualified
  - Policy content neutral and sourced

Formatting_Final_Check:
  - No English punctuation in Chinese text
  - No stray formatting characters
  - Consistent bullet/numbering style
  - Proper emoji usage (not excessive)
  - Line breaks appropriate (not too many blank lines)

Metadata_Verification:
  - Article date correct
  - Word count within range (6000-8000)
  - All required sections present:
    * å¼•å¯¼è¯­ (Opening hook)
    * 48å°æ—¶ç„¦ç‚¹ (Focus highlights)
    * ä¸»è¦å†…å®¹ (Main sections)
    * å…è´£å£°æ˜ (Disclaimer)
    * ä¸‹æœŸé¢„å‘Š (Preview)
    * è®¢é˜…æç¤º (Subscription prompt)
```

**Verification Process**:
```python
def final_quality_assurance(content):
    """
    Comprehensive final verification before publication
    """
    issues = []
    fixes_applied = []

    # Content verification
    content, content_issues = verify_content_accuracy(content)
    issues.extend(content_issues)

    # Structure verification
    structure_issues = verify_structure(content)
    issues.extend(structure_issues)

    # Compliance final check
    compliance_issues = final_compliance_check(content)
    if compliance_issues:
        issues.extend(compliance_issues)
        # Critical: terminate if compliance issues found in final check
        return content, issues, fixes_applied, "FAIL"

    # Formatting final check
    content, format_fixes = final_format_check(content)
    fixes_applied.extend(format_fixes)

    # Metadata verification
    metadata_issues = verify_metadata(content)
    issues.extend(metadata_issues)

    # Generate quality score
    quality_score = calculate_final_quality_score(content, issues)

    status = "PASS" if quality_score >= 85 else "WARNING"
    if len([i for i in issues if i['severity'] == 'critical']) > 0:
        status = "FAIL"

    return content, issues, fixes_applied, status

def verify_content_accuracy(content):
    """
    Check for consistency and accuracy issues
    """
    issues = []

    # Company name consistency
    company_variations = detect_company_name_variations(content)
    if company_variations:
        # Standardize to most common variation
        content = standardize_company_names(content, company_variations)
        for variation in company_variations:
            issues.append({
                'type': 'consistency',
                'severity': 'minor',
                'description': f"Company name variations: {variation['variations']}",
                'fixed': True
            })

    # Number formatting consistency
    number_inconsistencies = detect_number_format_inconsistencies(content)
    if number_inconsistencies:
        content = standardize_number_format(content)
        issues.append({
            'type': 'consistency',
            'severity': 'minor',
            'description': 'Number format inconsistencies detected and fixed',
            'fixed': True
        })

    return content, issues
```

**Output**:
```markdown
### Round 5: Final Quality Assurance

**Verification Completed**: âœ… All checks passed

#### Content Verification
- Company name consistency: âœ… All standardized
- Product name accuracy: âœ… Verified against official sources
- Number formatting: âœ… Consistent (ä¸­æ–‡æ•°å­—æ ¼å¼)
- Date formatting: âœ… Consistent (YYYYå¹´MMæœˆDDæ—¥)
- Currency labels: âœ… All properly marked

#### Structure Verification
- Table of contents: âœ… Matches sections
- Heading hierarchy: âœ… No skipped levels
- Section balance: âœ… Reasonable length distribution
- "48å°æ—¶ç„¦ç‚¹": âœ… Exactly 5 items

#### Compliance Final Check
- High-risk keywords: âœ… 0 remaining (all neutralized)
- Disclaimers: âœ… Present in all required locations
- Financial qualifications: âœ… All properly marked
- Policy content: âœ… Neutral and sourced

#### Formatting Final Check
- Punctuation: âœ… 100% Chinese in Chinese text
- Formatting characters: âœ… Clean
- Bullet style: âœ… Consistent
- Emoji usage: âœ… Appropriate
- Line breaks: âœ… Proper spacing

#### Metadata Verification
- Article date: âœ… 2025-11-20
- Word count: âœ… 7,234 words (within 6000-8000 range)
- Required sections: âœ… All present

#### Minor Issues Fixed (Non-critical)
1. Standardized "OpenAI" (was: "OpenAI" and "Open AI")
2. Fixed number format: "1000äº¿" (was: "100billion")
3. Adjusted section break spacing (removed excessive blank lines)

**Final Quality Score**: 94/100 (Excellent - Ready for Publication)
**Status**: âœ… PASS
```

## Optional Enhancement Rounds

### Round 6: Engagement Optimization (Optional)

- Add rhetorical questions to engage readers
- Insert relevant analogies for complex concepts
- Enhance storytelling elements
- Optimize reading flow

### Round 7: SEO Optimization (Optional)

- Keyword density optimization
- Meta description generation
- Tag suggestions
- Related content recommendations

### Round 8: Visual Element Suggestions (Optional)

- Identify locations for infographics
- Suggest chart types for data visualization
- Recommend image placements
- Note sections that would benefit from visual aids

## Output Format

### 1. Format Report (format_report_[DATE].md)

```markdown
# Tech News Formatting Report | 2025-11-20

> **Execution Time**: 2025-11-20 16:45:00 CST
> **Input File**: tech_news_20251120_wechat_draft.md
> **Output File**: tech_news_20251120_wechat_final.md
> **Overall Status**: âœ… PASS

---

## Executive Summary

- Total Optimization Rounds: 5 mandatory + 0 optional
- Total Changes Applied: 279 improvements
- Compliance Score: 95/100
- Grammar Score: 92/100
- Title Quality: 8.3/10
- Final Quality Score: 94/100
- **Verdict**: âœ… Ready for Publication

---

## Round-by-Round Summary

| Round | Focus | Changes | Score | Status |
|-------|-------|---------|-------|--------|
| 1 | Compliance | 23 | 95/100 | âœ… PASS |
| 2 | Punctuation | 187 | 100/100 | âœ… PASS |
| 3 | Grammar | 42 | 92/100 | âœ… PASS |
| 4 | Titles | 28 | 8.3/10 | âœ… PASS |
| 5 | QA | 3 fixes | 94/100 | âœ… PASS |

---

[Detailed output from each round as shown above]

---

## Before/After Comparison

### Key Improvements Showcase

#### Example 1: High-Risk Compliance Fix
**Before**: "ç¾å›½äº”è§’å¤§æ¥¼å®£å¸ƒæ–°çš„å†›äº‹AIåˆåŒï¼Œä»·å€¼20äº¿ç¾å…ƒï¼Œå¼•å‘ä¸­ç¾ç§‘æŠ€æˆ˜å‡çº§æ‹…å¿§ã€‚"

**After**: "ç¾å›½æ”¿åºœéƒ¨é—¨å®£å¸ƒæ–°çš„AIç ”å‘åˆä½œé¡¹ç›®ï¼Œä»·å€¼20äº¿ç¾å…ƒï¼ˆæ ¹æ®å…¬å¼€æŠ¥é“ï¼Œæœªç»å®˜æ–¹ç¡®è®¤ï¼‰ã€‚è¿™ä¸€ä¸¾æªåæ˜ äº†ä¸­ç¾åœ¨ç§‘æŠ€æ”¿ç­–æ–¹é¢çš„å·®å¼‚ã€‚"

**Changes**:
- "äº”è§’å¤§æ¥¼" â†’ "æ”¿åºœéƒ¨é—¨"
- "å†›äº‹AIåˆåŒ" â†’ "AIç ”å‘åˆä½œé¡¹ç›®"
- "ä¸­ç¾ç§‘æŠ€æˆ˜" â†’ "ä¸­ç¾ç§‘æŠ€æ”¿ç­–å·®å¼‚"
- Added financial disclaimer

#### Example 2: Punctuation and Grammar Combined
**Before**: "OpenAIçš„CEO Sam Altmanè¡¨ç¤º:\"GPT-5å°†ä¼šå½»åº•æ”¹å˜æ•´ä¸ªè¡Œä¸š, å®ƒçš„èƒ½åŠ›æ˜¯å‰æ‰€æœªæœ‰çš„.\""

**After**: "OpenAIé¦–å¸­æ‰§è¡Œå®˜Sam Altmanè¡¨ç¤ºï¼š"GPT-5æœ‰æœ›ä¸ºè¡Œä¸šå¸¦æ¥é‡è¦å˜é©ï¼Œå…¶èƒ½åŠ›æ˜¾è‘—è¶…è¶Šæ­¤å‰çš„æ¨¡å‹ã€‚""

**Changes**:
- "OpenAIçš„CEO" â†’ "OpenAIé¦–å¸­æ‰§è¡Œå®˜"
- English colon â†’ Chinese colon
- English quotes â†’ Chinese quotes
- English comma â†’ Chinese comma
- English period â†’ Chinese period
- "å½»åº•æ”¹å˜" â†’ "å¸¦æ¥é‡è¦å˜é©" (toned down)
- "å‰æ‰€æœªæœ‰" â†’ "æ˜¾è‘—è¶…è¶Šæ­¤å‰" (more specific)

#### Example 3: Headline Enhancement
**Before**: "Anthropicè·å¾—æŠ•èµ„"

**After**: "Anthropicè·Amazon 50äº¿ç¾å…ƒæŠ•èµ„ï¼Œä¼°å€¼è¾¾200äº¿ç¾å…ƒ"

**Changes**:
- Added investor name (Amazon)
- Added specific amount (50äº¿ç¾å…ƒ)
- Added valuation (200äº¿ç¾å…ƒ)
- Headline score: 3.5/10 â†’ 9.0/10

---

## Publication Readiness Checklist

âœ… Content Quality
  - âœ… All facts verified and sourced
  - âœ… Grammar and spelling correct
  - âœ… Consistent terminology throughout
  - âœ… Clear and engaging writing

âœ… Compliance
  - âœ… All sensitive keywords neutralized
  - âœ… Disclaimers added where required
  - âœ… Tone appropriate for Chinese market
  - âœ… No policy violations

âœ… Formatting
  - âœ… Chinese punctuation throughout
  - âœ… Consistent structure and hierarchy
  - âœ… Proper emoji usage
  - âœ… Clean formatting (no artifacts)

âœ… WeChat Requirements
  - âœ… Word count: 6,000-8,000 âœ“ (7,234)
  - âœ… Engaging title and opening
  - âœ… Clear table of contents
  - âœ… "48å°æ—¶ç„¦ç‚¹" section with 5 items
  - âœ… Proper ending (disclaimer + preview + subscription)

---

## Workflow Integration

- Format Status: âœ… PASS
- Output Files:
  - âœ… format_report_20251120.md (this file)
  - âœ… tech_news_20251120_wechat_final.md
- Next Phase: Publication / Export to Word
- Manual Review: Not required (quality score >90)

---

**Generated by**: daily-tech-news-formatter v4.0.0
**Execution Time**: 4 minutes 32 seconds
**Optimization Engine**: Rule-based (60%) + LLM-assisted (40%)
**Report Format**: v4.0-standard
```

### 2. Final Formatted Article (tech_news_[DATE]_wechat_final.md)

Standard WeChat-ready markdown with all optimizations applied.

## Integration with Workflow

### Input Requirements
- **File**: `tech_news_[YYYYMMDD]_wechat_draft.md` from daily-tech-news-writer
- **Format**: Markdown with WeChat structure
- **Status**: Must pass validator and writer phases

### Output Guarantees
- **Report**: `format_report_[YYYYMMDD].md` ALWAYS generated
- **Article**: `tech_news_[YYYYMMDD]_wechat_final.md` only if formatting succeeds
- **Status**: Explicit PASS/WARNING/FAIL in report

## Reference Documentation

- **[optimization_rules.md](references/optimization_rules.md)** - Complete optimization rule specifications
- **[sensitive_keywords.md](references/sensitive_keywords.md)** - 100+ keyword substitution rules (inherited from writer skill)
- **[punctuation_guide.md](references/punctuation_guide.md)** - Chinese/English punctuation usage rules
- **[title_patterns.md](references/title_patterns.md)** - Headline and title best practices

---

**Version**: 4.0.0
**Optimization Engine**: Rule-based (60%) + LLM-assisted (40%)
**Rounds**: 5 mandatory + 3 optional
**Quality Gate**: 85/100 minimum for publication approval
**Report Generation**: Always (even on failure)
